<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My</title>


    <script src="./assets/js/model-viewer-umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/howler@2.2.3/dist/howler.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/RecordRTC/5.6.2/RecordRTC.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/wavesurfer.js"></script>
    <script src="../component/Bubbles.js"></script>

    <link rel="stylesheet" media="all" href="../component/styles/setup.css">
	<link rel="stylesheet" media="all" href="../component/styles/says.css">
	<link rel="stylesheet" media="all" href="../component/styles/reply.css">
	<link rel="stylesheet" media="all" href="../component/styles/typing.css">
	<link rel="stylesheet" media="all" href="../component/styles/input.css">
    <style>
        body {
            padding: 0;
            margin: 0;
        }
        
        model-viewer {
            width: 100%;
            height: 100vh;
        }
        #waveform{
            position: absolute;
    top: 10em;
    /* padding: 3em; */
    left: 10%;
    width: 80%;
    user-select: none;
    z-index: 0;
        }

        .bubble-container {
            height: 100vh;
            background: none!important;
        }
        .bubble-container .input-wrap textarea {
            margin: 0;
            width: calc(100% - 30px);
        }
        #user_input{
            position: absolute;
    /* top: 0; */
    left: 0;
    z-index: 99;
    height: 72px;
    bottom: 1em;
    margin: 2%;
    width: 96%;
        }
    </style>
</head>

<body>

    

    <div id="app" style="background: linear-gradient(hsl(129deg 100% 97%), hsl(213deg 100% 89%)); overflow-x: hidden;">

        <div style="
            position: absolute;
            left:0;
            top:0;
            width:100%;
            height: 100vh;
            display: flex;
            align-items: flex-start;
    justify-content: flex-end;
            ">
            <h4 style="font-size: 2em;
            margin: 2em;
            position: absolute;
            left: 0;">
                META-SHADOW
            </h4>
            <div id="waveform"></div>
            <div id="chat"></div>
        </div>
            <model-viewer src="./assets/model/base-shadow.glb" ar ar-modes="webxr scene-viewer quick-look" 
            camera-controls poster="./assets/image/poster.webp" 
            autoplay animation-name="Idle"
            shadow-intensity="1" autoplay style="background-color: unset;">
                <button class="Hotspot" slot="hotspot-1" data-position="0.16843323423898407m 1.4220791200168543m -0.007215726788095456m" data-normal="-0.3923983733134677m 0.025428432508705207m 0.9194438054830186m" data-visibility-attribute="visible">
                    <div class="HotspotAnnotation" id="hotspot-hello">hi</div>
                </button>
                <div class="progress-bar hide" slot="progress-bar">
                    <div class="update-bar"></div>
                </div>
                <button slot="ar-button" id="ar-button">
                    View in your space
                </button>
                <div id="ar-prompt">
                    <img src="https://modelviewer.dev/shared-assets/icons/hand.png">
                </div>
            </model-viewer>

            <div class="bubble-container" id="user_input" >
                <div class="input-wrap"><textarea placeholder="Ask me anything..."></textarea></div>
            </div>
            

    </div>
    <!--     

    <model-viewer src="./assets/model/base-shadow.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls 
    poster="./assets/image/poster.webp" shadow-intensity="1" autoplay>
        <div class="progress-bar hide" slot="progress-bar">
            <div class="update-bar"></div>
        </div>
        <button slot="ar-button" id="ar-button">
            View in your space
        </button>
        <div id="ar-prompt">
            <img src="https://modelviewer.dev/shared-assets/icons/hand.png">
        </div>
    </model-viewer> -->
    <script>
        document.querySelector('#user_input textarea').addEventListener('input',e=>{
            if(e.inputType=="insertLineBreak"){
                console.log(e.target.value)
                userInput(e.target.value);
            }
        })

        var chatWindow = new Bubbles(document.getElementById("chat"), "chatWindow");

        function userInput(question){
            // let question='';
            var convo = {
                ice: {says: [],
                reply: [
                    {
                        question
                    },
                    
                ],
                },
            };
            chatWindow.talk(convo)
        }
        function chatbotSays(t){
             // let question='';
             var convo = {
                ice: {says: [t],
                reply: [],
                },
            };
            chatWindow.talk(convo)
        }

        


        window.oscillate = function(min, max, period, time) {
        const mag = max - min;
        return Math.cos(Math.PI + 2 * Math.PI * time / period) * (min + mag / 2.0) +
            mag / 2.0;
        };


        initHuman().then(w => window.human = w);

        // async function listening() {
        //     let stream = await navigator.mediaDevices.getUserMedia({
        //         video: false,
        //         audio: true
        //     });
        //     let recorder = new RecordRTCPromisesHandler(stream, {
        //         type: 'audio'
        //     });
        //     recorder.startRecording();

        //     const sleep = m => new Promise(r => setTimeout(r, m));
        //     await sleep(3000);

        //     await recorder.stopRecording();
        //     let base64 = await recorder.getDataURL()
        //         // invokeSaveAsDialog(blob);
        //     console.log(recorder)
        //     return base64
        // }

        // 网络请求
        const baseUrl=window.location.protocol + '//' + window.location.hostname + ":7860/run/audio_lip";
        function baseFetch(text=null,base64=null,type='tts'){
            
            //  type : tts,text-chatbot,lip
            return new Promise((res, rej) => {
                fetch(baseUrl, {
                        method: "POST",
                        headers: {
                            "Content-Type": "application/json"
                        },
                        body: JSON.stringify({
                            data: [
                                text, base64?{
                                    "name": "audio.wav",
                                    "data": base64
                                }:null,
                                type,
                            ]
                        })
                    })
                    .then(r => r.json())
                    .then(
                        r => res(r.data)
                    ).catch(e=>res(e))
            })
      

        }


        function fetchUserInputFromAudio(text) {
            return baseFetch(text,null,'tts')
        }

        function fetchUserInputFromText(text) {
            return baseFetch(text,null,'text-chatbot')
        }

        function fetchLipData(base64) {
            return baseFetch(null,base64,'lip')
        }

        // 打开本地的音频文件wav
        function openAudioFile() {
            let input = document.createElement('input')
            input.type = 'file'
            input.click();
            return new Promise((res, rej) => {
                input.addEventListener('change', e => {
                    let reader = new FileReader();
                    reader.readAsDataURL(input.files[0]);
                    reader.onloadend = e => {
                        res(e.target.result)
                    }
                })
            })

        }


        

        function recognitionUserInput(infoDiv) {
            console.log('recognition++start---------')
            if (window.recognition == undefined) {
                // 创建一个SpeechRecognition对象
                window.recognition = new webkitSpeechRecognition();
                window.recognition.state=0;
                // 配置设置以使每次识别都返回连续结果
                window.recognition.continuous = true;
                window.recognition.maxAlternatives = 1;
                // 配置应返回临时结果的设置
                window.recognition.interimResults = false;
                window.recognition.lang = 'zh';

                if(window.recognition.state==0)window.recognition.start();

                window.recognition.onerror = function(e) {
                    console.log('recognition++'+e.error)
                    // console.log('recognition++onerror');
                    // error 并不会导致自动end，end是有事件的，所以只需在end的时候再start即可
                    // if(window.recognition.state==0)window.recognition.start();

                    if(infoDiv)infoDiv.innerText=e.error;
                }

                // 正确识别单词或短语时的事件处理程序
                window.recognition.onresult = function(event) {
                    console.log('recognition++onresult');
                    
                    // 最新的回复
                    let text =Array.from(event.results,r=>r[0]).pop().transcript;
                    
                    console.log(window.humanIsPlay, text,Array.from(event.results,r=>r[0]));
                    
                    // chatbot bubble
                    // if(infoDiv)infoDiv.innerText=text;

                    // window.recognition.stop();
                    if (!window.humanIsPlay && text) {
                        window.humanIsPlay = true;
                        // window.recognition.stop();
                        window.human.thinking();
                        if(infoDiv)infoDiv.innerText='thinking';

                        userInputByText(text).then(() => {
                            // if(window.recognition.state==0)window.recognition.start();
                            window.humanIsPlay = false;
                            if(window.recognition.state==0)window.recognition.start();
                        })
                    }

                };

                window.recognition.onspeechstart = function() {
                    // window.human.thinking();
                    console.log('recognition++onspeechstart');
                    // window.recognition.stop();
                    
                }
                window.recognition.onspeechend = function() {
                    console.log('recognition++onspeechend');
                    // window.human.thinking();
                    // window.recognition.stop();
                }
                window.recognition.onaudioend = function() {
                    console.log('recognition++onaudioend');
                    window.human.idle();
                    // window.recognition.stop();
                }

                window.recognition.onaudiostart = function() {
                    console.log('recognition++onaudiostart');
                    
                    // 禁止发api
                    // window.humanIsPlay = true;
                    // if(window.recognition.state==0)window.recognition.start();
                }

                window.recognition.onsoundstart = function() {
                    console.log('recognition++onsoundstart')
                }

                window.recognition.onstart = function() {
                    console.log('recognition++onstart')
                    window.recognition.state=1;
                    setTimeout(()=>window.human.listening(),3500);
                }

                window.recognition.onend = function() {
                    console.log('recognition++onend')
                    window.recognition.state=0;
                    if(window.recognition.state==0)window.recognition.start();
                }

            } else {
                if(window.recognition.state==0)window.recognition.start();
            }

        }

        function userInputByText(text) {
            return new Promise((res, rej) => {
                fetchUserInputFromText(text).then(data => {
                    if(data) {start({...data[1] }).then(()=>res())}else{res();};
                })
            });
        }

        // 测试
        function audio2LipSync() {
            window.human.idle();
            openAudioFile().then(base64 => {
                fetchLipData(base64).then(res=>{
                    let data={...res[1],base64};
                    start(data);
                });
            })
        }

        


        function initHuman() {
            const playMouth=(object, json) =>{
            // let object=this;
            let data = {...json
            };

            let values = new Array(object.children[1].morphTargetInfluences.length).fill(
                0
            )

            for (let k in data) {

                let index = object.children[1].morphTargetDictionary[k];
                //   console.log(values[index],data[k])
                if (data[k] != undefined) {
                    values[index] = data[k]
                };
            }
            // console.log(object,values)
            object.children[1].morphTargetInfluences = [...values]
        };

            return new Promise((res, rej) => {
                //    let v=document.querySelector('#editing_adapter');
                //    let  m=v.shadowRoot.children[0]
                let modelViewer = document.querySelector('model-viewer');
                modelViewer.addEventListener('load', e => {

                    (() => {
                        const time = performance.now();
                        const app=document.querySelector('#app');
                        let color=Math.ceil(Math.random()*360);
                        app.setAttribute('data-color',color);
                        const animate = (now) => {
                            // 当在播放嘴型的时候，禁止背景变化，提高性能
                            if(window.human&&!window.human.humanIsPlay||window.human&&window.human.humanIsPlay==undefined){
                                modelViewer.shadowIntensity = oscillate(0, 2, 4000, now - time);
                                // bg 动画
                                let color=Math.ceil(app.getAttribute('data-color'));
                                color++;
                                if(color>360)color=0;
                                app.setAttribute('data-color',color);
                                app.style.background=`linear-gradient(hsl(${color}deg 100% 97%), hsl(${360-color}deg 100% 89%))`;
                            }
                           
                            requestAnimationFrame(animate);
                        };

                        animate();
                    })();

                    modelViewer.querySelectorAll('button').forEach((hotspot) => {
                        hotspot.addEventListener('click', () => {
                            console.log(hotspot.innerText)
                            let annotation=hotspot.querySelector('.HotspotAnnotation');
                            
                            if (annotation.id == 'hotspot-hello') {
                                window.action='greeting';
                                userInputByText('hello').then(() => {
                                    // console.log('0000')
                                    recognitionUserInput(annotation);
                                })
                            }

                        });
                    });


                    let scene = modelViewer.model.getThreeScene()
                    let object = scene.children[0];

                    modelViewer.playMouth = d => {
                        console.log('###playMouth')
                        modelViewer.animationName = 'Talk';
                        playMouth(object, d);
                    };
                    modelViewer.idle = () => {
                        console.log('###idle')
                        modelViewer.animationName = 'Idle';
                    };
                    modelViewer.thinking = () => {
                        console.log('###thinking')
                        modelViewer.animationName = 'Gesture-Head';
                        modelViewer.play({
                            repetitions:1
                        })
                    };
                    modelViewer.listening = () => {
                        console.log('###listening')
                        modelViewer.animationName = 'Looking';
                        // userInputByText('hello').then(() => {
                        //     recognitionUserInput();
                        // })
                        modelViewer.play({
                            repetitions:2
                        })
                    };

                    modelViewer.greeting=()=>{
                        console.log('###greeting')
                        modelViewer.animationName = 'Gesture--Greeting';
                        modelViewer.play({
                            repetitions:1
                        })
                    }

                    // 音频
                    modelViewer.playAudio=(base64,isUI=false)=>{
                        return new Promise((res, rej) => {
                            if(isUI){
                                if(window.wavesurfer==undefined){
                                    window.wavesurfer = WaveSurfer.create({
                                        container: document.querySelector('#waveform'),
                                        barMinHeight:10,
                                        cursorWidth:0,
                                        interact:false
                                    });

                                    window.wavesurfer.on('ready',()=>{
                                        window.wavesurfer.play()
                                    });
                                    
                                };
                                
                                window.wavesurfer.load(base64);
                                
                                window.wavesurfer.on('play',()=>{
                                    res(window.wavesurfer);
                                    window.wavesurfer.un('play')
                                });

                            }else{
                                window.sound = new Howl({
                                    src: [base64]
                                });
                                if (sound.state() == 'loaded') {
                                    window.sound.play();
                                    res(sound);
                                } else {
                                    // Clear listener after first call.
                                    sound.once('load', function() {
                                        window.sound.play();
                                        res(sound);
                                    });
                                };
                            }
                            
                        });
                    }

                    // modelViewer.playAudioUI=base64=>{
                    //     let wavesurfer = WaveSurfer.create({
                    //         container: document.querySelector('#waveform'),
                    //         barHeight:10
                    //     });
                    //     wavesurfer.load(base64);
                    //     wavesurfer.on('ready',()=>{
                    //         wavesurfer.play()
                    //         res(wavesurfer);
                    //     });
                    // }
                    
                    // 初始化完成
                    // console.log(m)
                    modelViewer.idle();
                    res(modelViewer);
                })

            })

        };

        // function audioPlayUI(data){
        //     let d={...data};
        //     let url=d.base64;
        //     var wavesurfer = WaveSurfer.create({
        //         container: document.querySelector('#waveform'),
        //         barHeight:10
        //     });
        //     wavesurfer.load(url);
        //     wavesurfer.on('ready',()=>{
        //         // delete d.base64;
        //         wavesurfer.play()
        //         start(d);
        //     });
        //     wavesurfer.on('finish',()=>{
        //         console.log('###Finished!');
        //     })
        // }


        // 驱动数字人-播放声音和动作
        function start(data,isUI=true) {
            window.human.humanIsPlay=true;

            window.data = data;
            window.preTime = (new Date()).getTime();
            window.fps = data.fps;
            window.maxFrameIndex = data.frames.length - 1;
            window.currentTime = 0;
            window.duration = data.duration * 1000;
            window.requestAnimationFrame(play);

            // 在聊天界面上显示出文字
            if(data.text){
                chatbotSays(data.text);
            }

            return new Promise((res,rej)=>{
                if(data.base64){
                        window.human.playAudio(data.base64,isUI).then(audio=>{

                            if(isUI){
                                audio.on('finish',()=>{
                                    console.log('###Finished!');
                                    window.human.idle();
                                    window.human.humanIsPlay=false;
                                    res();
                                })
                            }else{
                                audio.once('end', function() {
                                    console.log('###Finished!');
                                    // window.sound.off('end');
                                    window.human.idle();
                                    window.human.humanIsPlay=false;
                                    res()
                                });
                            }
                            // 动作播放,当有嘴型在播的时候，可以强制播放动作
                            if(window.action&&window.human[window.action]){
                                window.human[window.action]();
                            }
                    })
                }else{
                    window.human.humanIsPlay=false;
                    res();
                }
            })
        }

        function play() {
            let t = (new Date()).getTime();
            if (t - window.preTime > 1000 / window.fps) {

                window.currentTime += t - window.preTime;
                let index = Math.min(window.maxFrameIndex, Math.ceil(window.maxFrameIndex * window.currentTime / window.duration) - 1);
                //   console.log(index,window.currentTime,window.duration,data.frames[index]);
                // 播放
                window.human.playMouth(window.data.frames[index].viseme);
                window.preTime = t;

            };
            if (window.currentTime < window.duration) {
                window.requestAnimationFrame(play)
            } else {
                //嘴型动画播完了
                window.action=null;
            };
        }
    </script>
</body>

</html>